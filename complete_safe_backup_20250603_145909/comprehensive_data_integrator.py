#!/usr/bin/env python3)
# -*- coding: utf-8 -*-)
""")
HANAZONOã‚·ã‚¹ãƒ†ãƒ  6å¹´åˆ†ãƒ‡ãƒ¼ã‚¿çµ±åˆåˆ†æã‚·ã‚¹ãƒ†ãƒ  v1.0)
2018å¹´ã€œ2024å¹´ã®é›»åŠ›ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆåˆ†æ)
)
ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:)
- æœˆåˆ¥è©³ç´°: 2018å¹´5æœˆã€œ2022å¹´4æœˆ (4å¹´åˆ†))
- æ—¥åˆ¥è©³ç´°: 2022å¹´5æœˆã€œ2024å¹´4æœˆ (2å¹´åˆ†))
- å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿: 2024å¹´6æœˆã€œ2025å¹´5æœˆ (PDF))
""")
)
import pandas as pd)
import numpy as np)
import sqlite3)
import json)
import csv)
from datetime import datetime, timedelta)
from typing import Dict, List, Optional)
import logging)
)
class ComprehensiveDataIntegrator:)
    """6å¹´åˆ†é›»åŠ›ãƒ‡ãƒ¼ã‚¿çµ±åˆåˆ†æã‚·ã‚¹ãƒ†ãƒ """)
    )
    def __init__(self, db_path="data/comprehensive_electric_data.db"):)
        self.db_path = db_path)
        self.logger = self.setup_logger())
        self.init_database())
        )
        # ãƒ‡ãƒ¼ã‚¿æœŸé–“å®šç¾©)
        self.data_periods = {)
            "monthly_detail": {)
                "period": "2018-05 to 2022-04",)
                "description": "æœˆåˆ¥è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆæ˜¼å¤œåˆ†é›¢ãƒ»é›»æ°—æ–™é‡‘å«ã‚€ï¼‰",)
                "sources": [)
                    "tsukibetsuShiyoryo_201805-201904.txt",)
                    "tsukibetsuShiyoryo_201905-202004.txt", )
                    "tsukibetsuShiyoryo_202005-202104.txt",)
                    "tsukibetsuShiyoryo_202105-202204.txt")
                ])
            },)
            "daily_detail": {)
                "period": "2022-05 to 2024-04", )
                "description": "æ—¥åˆ¥è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆå¤©æ°—ãƒ»æ°—æ¸©ãƒ»æ—¥ç…§æ™‚é–“å«ã‚€ï¼‰",)
                "sources": [)
                    "hibetsuShiyoryo_202205-202304.txt",)
                    "hibetsuShiyoryo_202305-202404.txt")
                ])
            },)
            "hanazono_effect": {)
                "period": "2024-06 to 2025-05",)
                "description": "HANAZONOã‚·ã‚¹ãƒ†ãƒ åŠ¹æœæœŸé–“",)
                "sources": ["PDFæœˆåˆ¥é›»æ°—æ–™é‡‘è¡¨"])
            })
        })
    )
    def setup_logger(self):)
        """ãƒ­ã‚¬ãƒ¼è¨­å®š""")
        logger = logging.getLogger('ComprehensiveDataIntegrator'))
        logger.setLevel(logging.INFO))
        )
        if not logger.handlers:)
            handler = logging.FileHandler('logs/comprehensive_data_integration.log'))
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
            handler.setFormatter(formatter))
            logger.addHandler(handler))
        )
        return logger)
    )
    def init_database(self):)
        """çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–""")
        with sqlite3.connect(self.db_path) as conn:)
            cursor = conn.cursor())
            )
            # çµ±åˆæœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«)
            cursor.execute(''')
                CREATE TABLE IF NOT EXISTS comprehensive_monthly ()
                    id INTEGER PRIMARY KEY AUTOINCREMENT,)
                    year INTEGER NOT NULL,)
                    month INTEGER NOT NULL,)
                    usage_kwh REAL NOT NULL,)
                    cost_yen INTEGER,)
                    daytime_kwh REAL,)
                    nighttime_kwh REAL,)
                    avg_temp_high REAL,)
                    avg_temp_low REAL,)
                    co2_kg REAL,)
                    data_source TEXT NOT NULL,)
                    phase TEXT NOT NULL, -- baseline, covid, price_hike, pre_hanazono, hanazono)
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,)
                    UNIQUE(year, month))
                ))
            '''))
            )
            # çµ±åˆæ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«  )
            cursor.execute(''')
                CREATE TABLE IF NOT EXISTS comprehensive_daily ()
                    id INTEGER PRIMARY KEY AUTOINCREMENT,)
                    date TEXT NOT NULL UNIQUE,)
                    year INTEGER NOT NULL,)
                    month INTEGER NOT NULL,)
                    day INTEGER NOT NULL,)
                    weekday TEXT NOT NULL,)
                    usage_kwh REAL NOT NULL,)
                    weather TEXT,)
                    sunshine_hours REAL,)
                    temp_high REAL,)
                    temp_low REAL,)
                    data_source TEXT NOT NULL,)
                    phase TEXT NOT NULL,)
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)
                ))
            '''))
            )
            # é€²åŒ–ãƒ•ã‚§ãƒ¼ã‚ºå®šç¾©ãƒ†ãƒ¼ãƒ–ãƒ«)
            cursor.execute(''')
                CREATE TABLE IF NOT EXISTS evolution_phases ()
                    id INTEGER PRIMARY KEY AUTOINCREMENT,)
                    phase_name TEXT NOT NULL UNIQUE,)
                    start_date TEXT NOT NULL,)
                    end_date TEXT NOT NULL,)
                    description TEXT NOT NULL,)
                    key_events TEXT -- JSON format)
                ))
            '''))
            )
            conn.commit())
        )
        self.logger.info("çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†"))
    )
    def register_evolution_phases(self):)
        """é€²åŒ–ãƒ•ã‚§ãƒ¼ã‚ºã®ç™»éŒ²""")
        phases = [)
            {)
                "phase_name": "baseline",)
                "start_date": "2018-05-01",)
                "end_date": "2019-12-31", )
                "description": "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æœŸï¼ˆã‚³ãƒ­ãƒŠå‰ã®é€šå¸¸ç”Ÿæ´»ï¼‰",)
                "key_events": json.dumps(["é€šå¸¸ã®é›»åŠ›æ¶ˆè²»ãƒ‘ã‚¿ãƒ¼ãƒ³ç¢ºç«‹", "å­£ç¯€å¤‰å‹•ã®åŸºæº–å€¤è¨­å®š"]))
            },)
            {)
                "phase_name": "covid",)
                "start_date": "2020-01-01",)
                "end_date": "2021-12-31",)
                "description": "ã‚³ãƒ­ãƒŠå½±éŸ¿æœŸï¼ˆåœ¨å®…å‹¤å‹™ãƒ»è¡Œå‹•åˆ¶é™ï¼‰", )
                "key_events": json.dumps(["ç·Šæ€¥äº‹æ…‹å®£è¨€", "åœ¨å®…å‹¤å‹™å¢—åŠ ", "å¤–å‡ºè‡ªç²›"]))
            },)
            {)
                "phase_name": "price_hike", )
                "start_date": "2022-01-01",)
                "end_date": "2024-07-31",)
                "description": "é›»æ°—æ–™é‡‘é«˜é¨°å¯¾å¿œæœŸ",)
                "key_events": json.dumps(["é›»æ°—æ–™é‡‘é«˜é¨°", "ç¯€é›»æ„è­˜å‘ä¸Š", "ã‚¦ã‚¯ãƒ©ã‚¤ãƒŠæƒ…å‹¢å½±éŸ¿"]))
            },)
            {)
                "phase_name": "pre_hanazono",)
                "start_date": "2024-06-01", )
                "end_date": "2024-08-24",)
                "description": "HANAZONOã‚·ã‚¹ãƒ†ãƒ å°å…¥æº–å‚™æœŸ",)
                "key_events": json.dumps(["ã‚·ã‚¹ãƒ†ãƒ å°å…¥æ¤œè¨", "è¨­å‚™æº–å‚™"]))
            },)
            {)
                "phase_name": "hanazono",)
                "start_date": "2024-08-25",)
                "end_date": "2025-12-31",)
                "description": "HANAZONOã‚·ã‚¹ãƒ†ãƒ åŠ¹æœæœŸ",)
                "key_events": json.dumps(["ã‚½ãƒ¼ãƒ©ãƒ¼+è“„é›»æ± å°å…¥", "è‡ªå‹•æœ€é©åŒ–é–‹å§‹", "åŠ‡çš„å‰Šæ¸›åŠ¹æœ"]))
            })
        ])
        )
        with sqlite3.connect(self.db_path) as conn:)
            cursor = conn.cursor())
            )
            for phase in phases:)
                cursor.execute(''')
                    INSERT OR REPLACE INTO evolution_phases )
                    (phase_name, start_date, end_date, description, key_events))
                    VALUES (?, ?, ?, ?, ?))
                ''', (phase["phase_name"], phase["start_date"], phase["end_date"], )
                      phase["description"], phase["key_events"])))
            )
            conn.commit())
        )
        self.logger.info("é€²åŒ–ãƒ•ã‚§ãƒ¼ã‚ºç™»éŒ²å®Œäº†"))
    )
    def determine_phase(self, date_str: str) -> str:)
        """æ—¥ä»˜ã‹ã‚‰ãƒ•ã‚§ãƒ¼ã‚ºã‚’åˆ¤å®š""")
        date = datetime.strptime(date_str, '%Y-%m-%d'))
        )
        if date < datetime(2020, 1, 1):)
            return "baseline")
        elif date < datetime(2022, 1, 1):)
            return "covid" )
        elif date < datetime(2024, 8, 25):)
            return "price_hike")
        elif date < datetime(2024, 8, 25):)
            return "pre_hanazono")
        else:)
            return "hanazono")
    )
    def process_monthly_data(self, file_content: str, source_file: str):)
        """æœˆåˆ¥ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†""")
        lines = file_content.strip().split('\n'))
        )
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¢ã™)
        header_line = None)
        for i, line in enumerate(lines):)
            if 'æœˆåˆ†' in line and 'ä½¿ç”¨é‡' in line:)
                header_line = i)
                break)
        )
        if header_line is None:)
            self.logger.error(f"ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_file}"))
            return)
        )
        # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’å‡¦ç†)
        for line in lines[header_line + 1:]:)
            if not line.strip() or line.startswith('"ã”å¥‘ç´„ç•ªå·'):)
                continue)
                )
            try:)
                # CSVè¡Œã‚’ãƒ‘ãƒ¼ã‚¹)
                fields = self.parse_csv_line(line))
                )
                if len(fields) < 7:)
                    continue)
                )
                # å¹´æœˆåˆ†ã‚’è§£æ)
                year_month = fields[0].replace('å¹´', '-').replace('æœˆåˆ†', ''))
                year, month = map(int, year_month.split('-')))
                )
                usage_kwh = float(fields[6]) if fields[6] else 0)
                cost_yen = int(fields[10]) if fields[10] else 0)
                )
                # æ˜¼é–“ãƒ»å¤œé–“ä½¿ç”¨é‡)
                daytime_kwh = float(fields[7]) if len(fields) > 7 and fields[7] else None)
                nighttime_kwh = float(fields[9]) if len(fields) > 9 and fields[9] else None)
                )
                # æ°—æ¸©ãƒ‡ãƒ¼ã‚¿)
                avg_temp_high = float(fields[12]) if len(fields) > 12 and fields[12] else None)
                avg_temp_low = float(fields[13]) if len(fields) > 13 and fields[13] else None)
                )
                # CO2æ’å‡ºé‡)
                co2_kg = float(fields[14]) if len(fields) > 14 and fields[14] else None)
                )
                date_str = f"{year:04d}-{month:02d}-01")
                phase = self.determine_phase(date_str))
                )
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æŒ¿å…¥)
                with sqlite3.connect(self.db_path) as conn:)
                    cursor = conn.cursor())
                    cursor.execute(''')
                        INSERT OR REPLACE INTO comprehensive_monthly)
                        (year, month, usage_kwh, cost_yen, daytime_kwh, nighttime_kwh,)
                         avg_temp_high, avg_temp_low, co2_kg, data_source, phase))
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?))
                    ''', (year, month, usage_kwh, cost_yen, daytime_kwh, nighttime_kwh,)
                          avg_temp_high, avg_temp_low, co2_kg, source_file, phase)))
                )
                self.logger.info(f"æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ç™»éŒ²: {year}å¹´{month}æœˆ {usage_kwh}kWh"))
                )
            except Exception as e:)
                self.logger.error(f"æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {line[:50]}... - {e}"))
    )
    def process_daily_data(self, file_content: str, source_file: str):)
        """æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†""")
        lines = file_content.strip().split('\n'))
        )
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¢ã™)
        header_line = None)
        for i, line in enumerate(lines):)
            if 'æ—¥ä»˜' in line and 'ä½¿ç”¨é‡' in line:)
                header_line = i)
                break)
        )
        if header_line is None:)
            self.logger.error(f"ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_file}"))
            return)
        )
        # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’å‡¦ç†)
        for line in lines[header_line + 1:]:)
            if not line.strip() or line.startswith('"ã”å¥‘ç´„ç•ªå·'):)
                continue)
                )
            try:)
                fields = self.parse_csv_line(line))
                )
                if len(fields) < 7:)
                    continue)
                )
                date_str = fields[0])
                weekday = fields[1])
                usage_kwh = float(fields[2]) if fields[2] else 0)
                weather = fields[3] if len(fields) > 3 else None)
                sunshine_hours = float(fields[4]) if len(fields) > 4 and fields[4] else None)
                temp_high = float(fields[5]) if len(fields) > 5 and fields[5] else None  )
                temp_low = float(fields[6]) if len(fields) > 6 and fields[6] else None)
                )
                # æ—¥ä»˜ã‚’æ¨™æº–å½¢å¼ã«å¤‰æ›)
                date_parts = date_str.split('/'))
                if len(date_parts) == 3:)
                    year, month, day = map(int, date_parts))
                    standard_date = f"{year:04d}-{month:02d}-{day:02d}")
                    phase = self.determine_phase(standard_date))
                    )
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æŒ¿å…¥)
                    with sqlite3.connect(self.db_path) as conn:)
                        cursor = conn.cursor())
                        cursor.execute(''')
                            INSERT OR REPLACE INTO comprehensive_daily)
                            (date, year, month, day, weekday, usage_kwh, weather,)
                             sunshine_hours, temp_high, temp_low, data_source, phase))
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?))
                        ''', (standard_date, year, month, day, weekday, usage_kwh,)
                              weather, sunshine_hours, temp_high, temp_low, source_file, phase)))
                    )
                    self.logger.info(f"æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ç™»éŒ²: {standard_date} {usage_kwh}kWh"))
                )
            except Exception as e:)
                self.logger.error(f"æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {line[:50]}... - {e}"))
    )
    def parse_csv_line(self, line: str) -> List[str]:)
        """CSVè¡Œã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆå¯¾å¿œï¼‰""")
        fields = [])
        current_field = "")
        in_quotes = False)
        )
        for char in line:)
            if char == '"':)
                in_quotes = not in_quotes)
            elif char == ',' and not in_quotes:)
                fields.append(current_field.strip()))
                current_field = "")
            else:)
                current_field += char)
        )
        fields.append(current_field.strip()))
        return fields)
    )
    def analyze_6year_evolution(self) -> Dict:)
        """6å¹´é–“ã®é€²åŒ–åˆ†æ""")
        with sqlite3.connect(self.db_path) as conn:)
            # ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å¹´é–“ä½¿ç”¨é‡)
            phase_analysis = pd.read_sql_query(''')
                SELECT phase, )
                       COUNT(*) as months,)
                       AVG(usage_kwh) as avg_monthly_usage,)
                       SUM(usage_kwh) as total_usage,)
                       AVG(cost_yen) as avg_monthly_cost)
                FROM comprehensive_monthly )
                WHERE usage_kwh > 0 )
                GROUP BY phase )
                ORDER BY MIN(year), MIN(month))
            ''', conn))
            )
            # å¹´åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰)
            yearly_trend = pd.read_sql_query(''')
                SELECT year,)
                       SUM(usage_kwh) as annual_usage,)
                       AVG(usage_kwh) as avg_monthly_usage,)
                       SUM(cost_yen) as annual_cost,)
                       phase)
                FROM comprehensive_monthly )
                WHERE usage_kwh > 0)
                GROUP BY year )
                ORDER BY year)
            ''', conn))
            )
            return {)
                "phase_analysis": phase_analysis.to_dict('records'),)
                "yearly_trend": yearly_trend.to_dict('records'),)
                "data_summary": {)
                    "total_months": len(phase_analysis),)
                    "analysis_period": "2018-2025 (7å¹´é–“)",)
                    "phases_covered": phase_analysis['phase'].tolist())
                })
            })
    )
    def generate_comprehensive_report(self) -> str:)
        """ç·åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ""")
        analysis = self.analyze_6year_evolution())
        )
        report = "# HANAZONOã‚·ã‚¹ãƒ†ãƒ  6å¹´é–“ãƒ‡ãƒ¼ã‚¿çµ±åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n\n")
        report += f"**åˆ†ææœŸé–“**: {analysis['data_summary']['analysis_period']}\n")
        report += f"**å¯¾è±¡æœˆæ•°**: {analysis['data_summary']['total_months']}ãƒ¶æœˆ\n\n")
        )
        report += "## ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥åˆ†æ\n\n")
        for phase in analysis["phase_analysis"]:)
            report += f"### {phase['phase']}æœŸ\n")
            report += f"- æœŸé–“: {phase['months']}ãƒ¶æœˆ\n")
            report += f"- æœˆå¹³å‡ä½¿ç”¨é‡: {phase['avg_monthly_usage']:.1f}kWh\n")
            report += f"- æœˆå¹³å‡é›»æ°—ä»£: Â¥{phase['avg_monthly_cost']:,.0f}\n\n")
        )
        report += "## å¹´åˆ¥æ¨ç§»\n\n")
        for year in analysis["yearly_trend"]:)
            report += f"**{year['year']}å¹´** ({year['phase']}æœŸ): ")
            report += f"{year['annual_usage']:,.0f}kWh (æœˆå¹³å‡{year['avg_monthly_usage']:.1f}kWh)\n")
        )
        return report)
)
# ä½¿ç”¨ä¾‹)
def main():)
    integrator = ComprehensiveDataIntegrator())
    integrator.register_evolution_phases())
    )
    # åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ)
    report = integrator.generate_comprehensive_report())
    print(report))
    )
    print("âœ… 6å¹´åˆ†ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†"))
    print("ğŸ“Š ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ«ã®é›»åŠ›ä½¿ç”¨åˆ†æãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸï¼"))
)
if __name__ == "__main__":)
    main())
