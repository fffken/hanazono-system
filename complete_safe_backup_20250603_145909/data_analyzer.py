#!/usr/bin/env python3)
""")
HANAZONOã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¼ã‚¿åˆ†æã‚·ã‚¹ãƒ†ãƒ  v1.1ï¼ˆã‚¨ãƒ©ãƒ¼è€æ€§å¼·åŒ–ç‰ˆï¼‰)
æ©Ÿæ¢°å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒ»åˆ†æ)
""")
)
import json)
import pandas as pd)
import sqlite3)
import os)
from datetime import datetime, timedelta)
from pathlib import Path)
import glob)
)
class DataAnalyzer:)
    def __init__(self, data_dir="data"):)
        self.data_dir = Path(data_dir))
        self.db_path = self.data_dir / "hanazono_analysis.db")
        self.init_database())
    )
    def init_database(self):)
        """åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–""")
        self.data_dir.mkdir(exist_ok=True))
        )
        conn = sqlite3.connect(self.db_path))
        cursor = conn.cursor())
        )
        cursor.execute(''')
            CREATE TABLE IF NOT EXISTS system_data ()
                timestamp TEXT PRIMARY KEY,)
                datetime TEXT,)
                battery_soc INTEGER,)
                battery_voltage REAL,)
                battery_current REAL,)
                pv_power REAL,)
                load_power REAL,)
                grid_power REAL,)
                temperature REAL,)
                weather_condition TEXT,)
                season TEXT,)
                file_source TEXT)
            ))
        '''))
        )
        conn.commit())
        conn.close())
    )
    def analyze_file_structure(self, file_path):)
        """ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚’åˆ†æã—ã¦ã‚¨ãƒ©ãƒ¼ã®åŸå› ã‚’ç‰¹å®š""")
        try:)
            with open(file_path, 'r') as f:)
                content = f.read().strip())
            )
            if not content:)
                return "empty_file")
            )
            data = json.loads(content))
            )
            if data is None:)
                return "null_content")
            elif isinstance(data, list):)
                if len(data) == 0:)
                    return "empty_list")
                elif data[0] is None:)
                    return "null_first_element")
                else:)
                    return "valid_list")
            elif isinstance(data, dict):)
                return "valid_dict")
            else:)
                return "unknown_structure")
                )
        except json.JSONDecodeError:)
            return "invalid_json")
        except Exception as e:)
            return f"error_{type(e).__name__}")
    )
    def import_existing_data(self, analyze_errors=True):)
        """æ—¢å­˜JSONãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«çµ±åˆï¼ˆã‚¨ãƒ©ãƒ¼åˆ†æä»˜ãï¼‰""")
        json_files = glob.glob(str(self.data_dir / "lvyuan_data_*.json")))
        )
        conn = sqlite3.connect(self.db_path))
        imported_count = 0)
        error_stats = {})
        )
        print(f"ğŸ“ {len(json_files)}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­..."))
        )
        for file_path in json_files:)
            try:)
                with open(file_path, 'r') as f:)
                    content = f.read().strip())
                )
                if not content:)
                    if analyze_errors:)
                        error_stats["empty_file"] = error_stats.get("empty_file", 0) + 1)
                    continue)
                )
                data = json.loads(content))
                )
                if data is None:)
                    if analyze_errors:)
                        error_stats["null_content"] = error_stats.get("null_content", 0) + 1)
                    continue)
                )
                # ãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆ)
                if isinstance(data, list):)
                    if len(data) == 0:)
                        if analyze_errors:)
                            error_stats["empty_list"] = error_stats.get("empty_list", 0) + 1)
                        continue)
                    data = data[0])
                )
                # ãƒ‡ãƒ¼ã‚¿ãŒNoneã®å ´åˆ)
                if data is None:)
                    if analyze_errors:)
                        error_stats["null_data_element"] = error_stats.get("null_data_element", 0) + 1)
                    continue)
                )
                # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º)
                timestamp = data.get('timestamp'))
                datetime_str = data.get('datetime'))
                parameters = data.get('parameters', {}))
                )
                if not parameters:)
                    if analyze_errors:)
                        error_stats["no_parameters"] = error_stats.get("no_parameters", 0) + 1)
                    continue)
                )
                # ãƒãƒƒãƒ†ãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿æŠ½å‡º)
                battery_soc = None)
                battery_voltage = None)
                battery_current = None)
                )
                for key, param in parameters.items():)
                    if param and isinstance(param, dict):)
                        name = param.get('name', ''))
                        if 'SOC' in name:)
                            battery_soc = param.get('value'))
                        elif 'é›»åœ§' in name:)
                            battery_voltage = param.get('value'))
                        elif 'é›»æµ' in name:)
                            battery_current = param.get('value'))
                )
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æŒ¿å…¥)
                cursor = conn.cursor())
                cursor.execute(''')
                    INSERT OR REPLACE INTO system_data )
                    (timestamp, datetime, battery_soc, battery_voltage, battery_current, file_source))
                    VALUES (?, ?, ?, ?, ?, ?))
                ''', (timestamp, datetime_str, battery_soc, battery_voltage, battery_current, )
                      os.path.basename(file_path))))
                )
                imported_count += 1)
                )
            except Exception as e:)
                error_type = type(e).__name__)
                if analyze_errors:)
                    error_stats[f"exception_{error_type}"] = error_stats.get(f"exception_{error_type}", 0) + 1)
        )
        conn.commit())
        conn.close())
        )
        print(f"âœ… {imported_count}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ"))
        )
        if analyze_errors and error_stats:)
            print("\nğŸ“‹ ã‚¨ãƒ©ãƒ¼åˆ†æçµæœ:"))
            print("=" * 40))
            for error_type, count in sorted(error_stats.items()):)
                print(f"{error_type}: {count}ä»¶"))
        )
        return imported_count, error_stats)
    )
    def get_daily_summary(self, days=7):)
        """æ—¥æ¬¡ã‚µãƒãƒªãƒ¼å–å¾—""")
        conn = sqlite3.connect(self.db_path))
        )
        query = ''')
            SELECT )
                DATE(datetime) as date,)
                AVG(battery_soc) as avg_soc,)
                MIN(battery_soc) as min_soc,)
                MAX(battery_soc) as max_soc,)
                AVG(battery_voltage) as avg_voltage,)
                COUNT(*) as data_points)
            FROM system_data )
            WHERE datetime > datetime('now', '-{} days'))
            AND battery_soc IS NOT NULL)
            GROUP BY DATE(datetime))
            ORDER BY date DESC)
        '''.format(days))
        )
        df = pd.read_sql_query(query, conn))
        conn.close())
        )
        return df)
    )
    def analyze_performance(self):)
        """ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½åˆ†æ""")
        conn = sqlite3.connect(self.db_path))
        )
        # åŸºæœ¬çµ±è¨ˆ)
        stats_query = ''')
            SELECT )
                COUNT(*) as total_records,)
                COUNT(CASE WHEN battery_soc IS NOT NULL THEN 1 END) as valid_soc_records,)
                AVG(battery_soc) as avg_soc,)
                MIN(battery_soc) as min_soc,)
                MAX(battery_soc) as max_soc,)
                AVG(battery_voltage) as avg_voltage,)
                MIN(datetime) as first_record,)
                MAX(datetime) as last_record)
            FROM system_data)
            WHERE battery_soc IS NOT NULL)
        ''')
        )
        stats = pd.read_sql_query(stats_query, conn))
        )
        # ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ)
        quality_query = ''')
            SELECT )
                COUNT(*) as total_records,)
                COUNT(CASE WHEN battery_soc IS NULL THEN 1 END) as missing_soc,)
                COUNT(CASE WHEN battery_voltage IS NULL THEN 1 END) as missing_voltage,)
                COUNT(CASE WHEN battery_current IS NULL THEN 1 END) as missing_current)
            FROM system_data)
        ''')
        )
        quality = pd.read_sql_query(quality_query, conn))
        conn.close())
        )
        print("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½åˆ†æçµæœ:"))
        print("=" * 50))
        print(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {quality['total_records'].iloc[0]:,}"))
        print(f"æœ‰åŠ¹SOCãƒ¬ã‚³ãƒ¼ãƒ‰: {stats['valid_soc_records'].iloc[0]:,}"))
        print(f"å¹³å‡SOC: {stats['avg_soc'].iloc[0]:.1f}%"))
        print(f"æœ€ä½SOC: {stats['min_soc'].iloc[0]:.1f}%"))
        print(f"æœ€é«˜SOC: {stats['max_soc'].iloc[0]:.1f}%"))
        print(f"å¹³å‡é›»åœ§: {stats['avg_voltage'].iloc[0]:.1f}V"))
        print(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {stats['first_record'].iloc[0]} ã€œ {stats['last_record'].iloc[0]}"))
        )
        print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ:"))
        print("=" * 50))
        total = quality['total_records'].iloc[0])
        missing_soc = quality['missing_soc'].iloc[0])
        missing_voltage = quality['missing_voltage'].iloc[0])
        missing_current = quality['missing_current'].iloc[0])
        )
        print(f"SOCæ¬ æç‡: {(missing_soc/total*100):.1f}% ({missing_soc}ä»¶)"))
        print(f"é›»åœ§æ¬ æç‡: {(missing_voltage/total*100):.1f}% ({missing_voltage}ä»¶)"))
        print(f"é›»æµæ¬ æç‡: {(missing_current/total*100):.1f}% ({missing_current}ä»¶)"))
        )
        return stats, quality)
    )
    def get_hourly_pattern(self):)
        """æ™‚é–“åˆ¥SOCãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ""")
        conn = sqlite3.connect(self.db_path))
        )
        query = ''')
            SELECT )
                strftime('%H', datetime) as hour,)
                AVG(battery_soc) as avg_soc,)
                COUNT(*) as data_points)
            FROM system_data )
            WHERE battery_soc IS NOT NULL)
            GROUP BY strftime('%H', datetime))
            ORDER BY hour)
        ''')
        )
        df = pd.read_sql_query(query, conn))
        conn.close())
        )
        print("\nâ° æ™‚é–“åˆ¥SOCãƒ‘ã‚¿ãƒ¼ãƒ³:"))
        print("=" * 30))
        for _, row in df.iterrows():)
            hour = int(row['hour']))
            avg_soc = row['avg_soc'])
            points = row['data_points'])
            print(f"{hour:02d}æ™‚: {avg_soc:.1f}% ({points}ä»¶)"))
        )
        return df)
)
if __name__ == "__main__":)
    analyzer = DataAnalyzer())
    )
    print("ğŸš€ æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿åˆ†æã‚·ã‚¹ãƒ†ãƒ é–‹å§‹..."))
    print("1. æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­ï¼ˆã‚¨ãƒ©ãƒ¼åˆ†æä»˜ãï¼‰..."))
    imported, errors = analyzer.import_existing_data())
    )
    print("\n2. ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½åˆ†æä¸­..."))
    stats, quality = analyzer.analyze_performance())
    )
    print("\n3. æ—¥æ¬¡ã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­..."))
    summary = analyzer.get_daily_summary())
    print(summary.to_string(index=False)))
    )
    print("\n4. æ™‚é–“åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æä¸­..."))
    hourly = analyzer.get_hourly_pattern())
    )
    print("\nâœ… æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿åˆ†æå®Œäº†"))
    print(f"ğŸ¯ æ©Ÿæ¢°å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {imported}ä»¶ã®æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿"))
