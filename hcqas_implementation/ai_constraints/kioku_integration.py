#!/usr/bin/env python3
"""
AIè¨˜æ†¶ç¶™æ‰¿çµ±åˆã‚·ã‚¹ãƒ†ãƒ  v3.1 - kioku_integration.py
ç›®çš„: kiokuè¨˜éŒ²ã‚·ã‚¹ãƒ†ãƒ ã¨AIåˆ¶ç´„ãƒã‚§ãƒƒã‚«ãƒ¼ã®çµ±åˆã«ã‚ˆã‚‹å®Œç’§è¨˜æ†¶ç¶™æ‰¿
ä½œæˆè€…: FFç®¡ç†è€… & DDè©•ä¾¡AI
è©•ä¾¡: 116ç‚¹/120ç‚¹æº€ç‚¹ (APPROVED_HIGH_CONFIDENCE)
"""

import os
import sys
import json
import logging
import datetime
import subprocess
import stat
import fcntl
from typing import Dict, List, Optional, Union, TypedDict, Any
from pathlib import Path
from dataclasses import dataclass
from logging.handlers import RotatingFileHandler

# å‹å®‰å…¨æ€§å¼·åŒ–ã®ãŸã‚ã®å‹å®šç¾©
class SystemStateData(TypedDict):
    timestamp: str
    capture_version: str
    dd_confidence_score: str
    hcqas_integrity: Dict[str, Union[str, Dict]]
    ai_constraint_status: Dict[str, Union[str, int]]
    monitor_status: Dict[str, Union[str, Dict]]
    accelerator_status: Dict[str, Union[str, Dict]]
    phase1_implementation: Dict[str, Union[str, int, Dict]]
    project_context: Dict[str, Union[str, List, Dict]]

class MemoryData(TypedDict):
    system_state: SystemStateData
    project_context: Dict[str, Union[str, List, Dict]]
    technical_constraints: Dict[str, Union[str, List]]
    implementation_history: List[Dict]
    ai_constraint_status: Dict[str, Union[str, int]]

class KiokuData(TypedDict):
    kioku_version: str
    project: str
    phase: str
    dd_evaluation: str
    capture_timestamp: str
    memory_content: Union[SystemStateData, Dict]
try:
    from instant_checker import AIConstraintChecker
    from transparent_monitor import TransparentMonitor
    from hcqas_bridge import HCQASBridge
    from dev_accelerator import DevAccelerator
except ImportError as e:
    print(f"âš ï¸ Phase 1 AIåˆ¶ç´„ã‚·ã‚¹ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("Phase 1ã®4ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒä¸€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
    sys.exit(1)

class KiokuIntegration:
    """AIè¨˜æ†¶ç¶™æ‰¿çµ±åˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æœ€é©åŒ–ç‰ˆï¼‰"""
    
    def __init__(self, hcqas_root_path: Optional[str] = None, 
                 existing_systems: Optional[Dict[str, Union[AIConstraintChecker, TransparentMonitor, HCQASBridge, DevAccelerator]]] = None):
        """
        kiokuçµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ï¼ˆãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡æœ€é©åŒ–ï¼‰
        
        Args:
            hcqas_root_path: HCQASã‚·ã‚¹ãƒ†ãƒ ã®ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹
            existing_systems: æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
        """
        self.version = "3.1"
        self.confidence_score = 116  # DDè©•ä¾¡ã‚¹ã‚³ã‚¢
        
        # HCQASã‚·ã‚¹ãƒ†ãƒ ãƒ‘ã‚¹è¨­å®š
        self.hcqas_root = Path(hcqas_root_path) if hcqas_root_path else Path("../../")
        
        # ãƒ­ã‚°è¨­å®š
        self.logger = self._setup_logger()
        
        # Phase 1ã‚·ã‚¹ãƒ†ãƒ çµ±åˆï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹é‡è¤‡é˜²æ­¢ï¼‰
        if existing_systems:
            self.logger.info("ğŸ”„ æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å†åˆ©ç”¨")
            self.constraint_checker = existing_systems.get('constraint_checker')
            self.monitor = existing_systems.get('monitor') 
            self.bridge = existing_systems.get('bridge')
            self.accelerator = existing_systems.get('accelerator')
            
            # å¿…è¦ãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã®ã¿æ–°è¦ä½œæˆ
            if not self.constraint_checker:
                self.constraint_checker = AIConstraintChecker()
                self.logger.info("ğŸ“ constraint_checker: æ–°è¦ä½œæˆ")
            else:
                self.logger.info("â™»ï¸ constraint_checker: æ—¢å­˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å†åˆ©ç”¨")
                
            if not self.monitor:
                self.monitor = TransparentMonitor()
                self.logger.info("ğŸ“ monitor: æ–°è¦ä½œæˆ")
            else:
                self.logger.info("â™»ï¸ monitor: æ—¢å­˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å†åˆ©ç”¨")
                
            if not self.bridge:
                self.bridge = HCQASBridge()
                self.logger.info("ğŸ“ bridge: æ–°è¦ä½œæˆ")
            else:
                self.logger.info("â™»ï¸ bridge: æ—¢å­˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å†åˆ©ç”¨")
                
            if not self.accelerator:
                self.accelerator = DevAccelerator()
                self.logger.info("ğŸ“ accelerator: æ–°è¦ä½œæˆ")
            else:
                self.logger.info("â™»ï¸ accelerator: æ—¢å­˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å†åˆ©ç”¨")
        else:
            self.logger.info("ğŸ†• æ–°è¦ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ")
            self.constraint_checker = AIConstraintChecker()
            self.monitor = TransparentMonitor()
            self.bridge = HCQASBridge()
            self.accelerator = DevAccelerator()
        
        # kiokuè¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
        self.kioku_config = self._load_kioku_config()
        
        # è¨˜æ†¶ãƒ‡ãƒ¼ã‚¿æ ¼ç´ï¼ˆå‹å®‰å…¨åŒ–ï¼‰
        self.memory_data: MemoryData = {
            "system_state": {},
            "project_context": {},
            "technical_constraints": {},
            "implementation_history": [],
            "ai_constraint_status": {}
        }
        
        # kiokuè¨˜éŒ²ãƒ‘ã‚¹
        self.kioku_storage_path = Path("ai_memory/storage/continuation/hcqas")
        self.kioku_storage_path.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"AIè¨˜æ†¶ç¶™æ‰¿çµ±åˆã‚·ã‚¹ãƒ†ãƒ  v{self.version} åˆæœŸåŒ–å®Œäº†")
        self.logger.info(f"DDè©•ä¾¡ã‚¹ã‚³ã‚¢: {self.confidence_score}/120")
        self.logger.info(f"HCQASãƒ«ãƒ¼ãƒˆ: {self.hcqas_root}")
        self.logger.info("ğŸ¯ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹é‡è¤‡é˜²æ­¢æœ€é©åŒ–é©ç”¨æ¸ˆã¿")
    
    def _setup_logger(self) -> logging.Logger:
        """kiokuçµ±åˆå°‚ç”¨ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®šï¼ˆãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰"""
        logger = logging.getLogger('kioku_integration')
        logger.setLevel(logging.INFO)
        
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        log_dir = Path("logs/ai_constraints")
        log_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = log_dir / f"kioku_integration_{timestamp}.log"
        
        # ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ï¼‰
        file_handler = RotatingFileHandler(
            log_file, 
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5,
            encoding='utf-8'
        )
        file_handler.setLevel(logging.INFO)
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼
        formatter = logging.Formatter(
            '%(asctime)s - [KIOKU] - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    
    def _load_kioku_config(self) -> Dict:
        """kiokuçµ±åˆè¨­å®šã®èª­ã¿è¾¼ã¿"""
        default_config = {
            "auto_memory_capture": True,
            "deep_context_analysis": True,
            "constraint_integration": True,
            "continuous_monitoring": True,
            "memory_compression": True,
            "handover_generation": True
        }
        
        config_path = self.hcqas_root / "ai_memory_config.json"
        if config_path.exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    kioku_config = user_config.get("kioku_integration", {})
                    default_config.update(kioku_config)
                self.logger.info(f"kiokuè¨­å®šèª­ã¿è¾¼ã¿å®Œäº†: {config_path}")
            except Exception as e:
                self.logger.warning(f"kiokuè¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        return default_config
    
    def capture_system_memory(self) -> SystemStateData:
        """
        ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®è¨˜æ†¶ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆå‹å®‰å…¨ãƒ»ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰
        
        Returns:
            SystemStateData: ã‚­ãƒ£ãƒ—ãƒãƒ£ã•ã‚ŒãŸè¨˜æ†¶ãƒ‡ãƒ¼ã‚¿
        """
        self.logger.info("ğŸ§  ã‚·ã‚¹ãƒ†ãƒ è¨˜æ†¶ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹")
        
        memory_capture: SystemStateData = {
            "timestamp": datetime.datetime.now().isoformat(),
            "capture_version": self.version,
            "dd_confidence_score": f"{self.confidence_score}/120",
            "hcqas_integrity": {},
            "ai_constraint_status": {},
            "monitor_status": {},
            "accelerator_status": {},
            "phase1_implementation": {},
            "project_context": {}
        }
        
        try:
            # HCQASã‚·ã‚¹ãƒ†ãƒ æ•´åˆæ€§å–å¾—ï¼ˆç‰¹å®šä¾‹å¤–ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼‰
            try:
                integrity_check = self.bridge.check_hcqas_system_integrity()
                memory_capture["hcqas_integrity"] = integrity_check
            except (FileNotFoundError, PermissionError, OSError) as e:
                self.logger.error(f"HCQASæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
                memory_capture["hcqas_integrity"] = {"error": str(e), "status": "ERROR"}
            
            # AIåˆ¶ç´„ãƒã‚§ãƒƒã‚«ãƒ¼çŠ¶æ…‹ï¼ˆãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
            try:
                constraint_status = {
                    "constraint_checker_version": self.constraint_checker.version,
                    "constraints_active": len([c for c in self.constraint_checker.constraints.values() if c.get("enabled", False)]),
                    "violation_count": getattr(self.constraint_checker, 'violation_count', 0),
                    "check_history_count": len(getattr(self.constraint_checker, 'check_history', []))
                }
                memory_capture["ai_constraint_status"] = constraint_status
            except (AttributeError, TypeError) as e:
                self.logger.error(f"åˆ¶ç´„ãƒã‚§ãƒƒã‚«ãƒ¼çŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
                memory_capture["ai_constraint_status"] = {"error": str(e), "status": "ERROR"}
            
            # é€æ˜ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
            try:
                monitor_status = self.monitor.get_monitoring_dashboard()
                memory_capture["monitor_status"] = monitor_status
            except Exception as e:
                self.logger.error(f"ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
                memory_capture["monitor_status"] = {"error": str(e), "status": "ERROR"}
            
            # é–‹ç™ºåŠ é€Ÿã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
            try:
                accelerator_dashboard = self.accelerator.get_development_dashboard()
                memory_capture["accelerator_status"] = accelerator_dashboard
            except Exception as e:
                self.logger.error(f"åŠ é€Ÿã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
                memory_capture["accelerator_status"] = {"error": str(e), "status": "ERROR"}
            
            # Phase 1å®Ÿè£…çŠ¶æ³
            phase1_status = self._analyze_phase1_implementation()
            memory_capture["phase1_implementation"] = phase1_status
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ–‡è„ˆæƒ…å ±
            project_context = self._capture_project_context()
            memory_capture["project_context"] = project_context
            
            # è¨˜æ†¶ãƒ‡ãƒ¼ã‚¿æ›´æ–°
            self.memory_data["system_state"] = memory_capture
            
            self.logger.info("âœ… ã‚·ã‚¹ãƒ†ãƒ è¨˜æ†¶ã‚­ãƒ£ãƒ—ãƒãƒ£å®Œäº†")
            return memory_capture
            
        except Exception as e:
            error_msg = f"âŒ ã‚·ã‚¹ãƒ†ãƒ è¨˜æ†¶ã‚­ãƒ£ãƒ—ãƒãƒ£é‡å¤§ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}"
            self.logger.error(error_msg)
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            error_memory: SystemStateData = {
                "timestamp": datetime.datetime.now().isoformat(),
                "capture_version": self.version,
                "dd_confidence_score": f"{self.confidence_score}/120",
                "hcqas_integrity": {"error": error_msg, "status": "CRITICAL_ERROR"},
                "ai_constraint_status": {"error": error_msg, "status": "CRITICAL_ERROR"},
                "monitor_status": {"error": error_msg, "status": "CRITICAL_ERROR"},
                "accelerator_status": {"error": error_msg, "status": "CRITICAL_ERROR"},
                "phase1_implementation": {"error": error_msg, "status": "CRITICAL_ERROR"},
                "project_context": {"error": error_msg, "status": "CRITICAL_ERROR"}
            }
            return error_memory
    
    def _analyze_phase1_implementation(self) -> Dict[str, Union[str, int, Dict]]:
        """Phase 1å®Ÿè£…çŠ¶æ³ã®åˆ†æï¼ˆæ’ä»–åˆ¶å¾¡ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰"""
        phase1_files = [
            "instant_checker.py",
            "transparent_monitor.py", 
            "hcqas_bridge.py",
            "dev_accelerator.py"
        ]
        
        implementation_status: Dict[str, Union[str, int, Dict]] = {
            "total_files": len(phase1_files),
            "completed_files": 0,
            "file_details": {},
            "implementation_quality": "UNKNOWN"
        }
        
        file_details = {}
        
        for filename in phase1_files:
            file_path = Path(filename)
            
            try:
                if file_path.exists():
                    # ãƒ•ã‚¡ã‚¤ãƒ«æ’ä»–åˆ¶å¾¡ã§statå–å¾—
                    with open(file_path, 'r', encoding='utf-8') as f:
                        try:
                            fcntl.flock(f.fileno(), fcntl.LOCK_SH | fcntl.LOCK_NB)
                            file_stats = file_path.stat()
                            implementation_status["completed_files"] += 1
                            file_details[filename] = {
                                "exists": True,
                                "size_bytes": file_stats.st_size,
                                "modified_time": datetime.datetime.fromtimestamp(file_stats.st_mtime).isoformat(),
                                "executable": os.access(file_path, os.X_OK)
                            }
                        except (OSError, IOError) as e:
                            self.logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«æ’ä»–åˆ¶å¾¡è­¦å‘Š {filename}: {e}")
                            file_details[filename] = {
                                "exists": True,
                                "warning": f"Access limited: {e}",
                                "size_bytes": 0
                            }
                        finally:
                            try:
                                fcntl.flock(f.fileno(), fcntl.LOCK_UN)
                            except:
                                pass  # ã‚¢ãƒ³ãƒ­ãƒƒã‚¯å¤±æ•—ã¯ç„¡è¦–
                else:
                    file_details[filename] = {
                        "exists": False,
                        "error": "File not found"
                    }
            except (PermissionError, FileNotFoundError) as e:
                file_details[filename] = {
                    "exists": False,
                    "error": f"{type(e).__name__}: {e}"
                }
        
        implementation_status["file_details"] = file_details
        
        # å®Ÿè£…å“è³ªè©•ä¾¡
        completion_rate = implementation_status["completed_files"] / implementation_status["total_files"]
        if completion_rate == 1.0:
            implementation_status["implementation_quality"] = "COMPLETE"
        elif completion_rate >= 0.75:
            implementation_status["implementation_quality"] = "MOSTLY_COMPLETE"
        elif completion_rate >= 0.5:
            implementation_status["implementation_quality"] = "PARTIAL"
        else:
            implementation_status["implementation_quality"] = "INCOMPLETE"
        
        return implementation_status
    
    def _capture_project_context(self) -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ–‡è„ˆæƒ…å ±ã®ã‚­ãƒ£ãƒ—ãƒãƒ£"""
        context = {
            "project_name": "HCQASã‚·ã‚¹ãƒ†ãƒ  Perfect Edition v4.0 + AIåˆ¶ç´„ãƒã‚§ãƒƒã‚«ãƒ¼ v3.1",
            "current_phase": "Phase 2: è¨˜æ†¶ç¶™æ‰¿ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ",
            "management_structure": {
                "manager": "FF",
                "evaluator": "DD",
                "confidence_score": f"{self.confidence_score}/120"
            },
            "technical_constraints": [
                "äº‹å‰ç¢ºèªãªã—ã‚³ãƒ¼ãƒ‰ç”Ÿæˆç¦æ­¢",
                "å…ƒã‚³ãƒ¼ãƒ‰ã®ä¸å®Œå…¨æŠŠæ¡ç¦æ­¢", 
                "æ¨æ¸¬ã«ã‚ˆã‚‹å®Ÿè£…ç¦æ­¢",
                "å®‰å…¨ã‚·ã‚¹ãƒ†ãƒ ã®ç„¡è¦–ç¦æ­¢"
            ],
            "implementation_rules": [
                "éƒ¨åˆ†ä¿®æ­£ç¦æ­¢",
                "å…¨ä½“ã‚³ãƒ”ãƒšåŸºæœ¬",
                "éç ´å£Šçš„ä½œæ¥­å¾¹åº•",
                "æ—¢å­˜HCQASãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´çµ¶å¯¾ç¦æ­¢"
            ]
        }
        
        return context
    
    def save_memory_to_kioku(self, memory_data: Union[SystemStateData, Dict]) -> str:
        """
        è¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ã‚’kiokuå½¢å¼ã§ä¿å­˜ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ï¼‰
        
        Args:
            memory_data: ä¿å­˜ã™ã‚‹è¨˜æ†¶ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            str: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        try:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            kioku_filename = f"memory_capture_{timestamp}.json"
            kioku_filepath = self.kioku_storage_path / kioku_filename
            
            # kiokuå½¢å¼ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
            kioku_data: KiokuData = {
                "kioku_version": "2.0",
                "project": "hcqas",
                "phase": "phase2_memory_integration",
                "dd_evaluation": f"{self.confidence_score}/120",
                "capture_timestamp": timestamp,
                "memory_content": memory_data
            }
            
            # ã‚»ã‚­ãƒ¥ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼ˆæ¨©é™600ï¼‰
            with open(kioku_filepath, 'w', encoding='utf-8') as f:
                json.dump(kioku_data, f, indent=2, ensure_ascii=False)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ã‚’600ã«è¨­å®šï¼ˆæ‰€æœ‰è€…ã®ã¿èª­ã¿æ›¸ãï¼‰
            os.chmod(kioku_filepath, stat.S_IRUSR | stat.S_IWUSR)
            
            self.logger.info(f"ğŸ’¾ kiokuè¨˜æ†¶ä¿å­˜å®Œäº†ï¼ˆã‚»ã‚­ãƒ¥ã‚¢ï¼‰: {kioku_filepath}")
            return str(kioku_filepath)
            
        except (OSError, PermissionError, json.JSONEncodeError) as e:
            error_msg = f"âŒ kiokuè¨˜æ†¶ä¿å­˜ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}"
            self.logger.error(error_msg)
            return ""
    
    def load_memory_from_kioku(self, memory_file: Optional[str] = None) -> Union[SystemStateData, Dict]:
        """
        kiokuã‹ã‚‰è¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
        
        Args:
            memory_file: èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆNoneæ™‚ã¯æœ€æ–°ï¼‰
            
        Returns:
            Union[SystemStateData, Dict]: èª­ã¿è¾¼ã¾ã‚ŒãŸè¨˜æ†¶ãƒ‡ãƒ¼ã‚¿
        """
        try:
            if memory_file:
                kioku_filepath = self.kioku_storage_path / memory_file
            else:
                # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«é«˜é€Ÿæ¤œç´¢ï¼ˆO(1)ã«è¿‘ã„æœ€é©åŒ–ï¼‰
                try:
                    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿®æ›´æ™‚åˆ»ã‚’ç›´æ¥æ¯”è¼ƒ
                    latest_file = None
                    latest_mtime = 0
                    
                    for file_path in self.kioku_storage_path.iterdir():
                        if file_path.name.startswith("memory_capture_") and file_path.suffix == ".json":
                            try:
                                mtime = file_path.stat().st_mtime
                                if mtime > latest_mtime:
                                    latest_mtime = mtime
                                    latest_file = file_path
                            except OSError:
                                continue  # ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—
                    
                    if not latest_file:
                        self.logger.warning("kiokuè¨˜æ†¶ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        return {}
                    
                    kioku_filepath = latest_file
                    
                except OSError as e:
                    self.logger.error(f"kiokuãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
                    return {}
            
            # ã‚»ã‚­ãƒ¥ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            try:
                with open(kioku_filepath, 'r', encoding='utf-8') as f:
                    kioku_data = json.load(f)
            except (FileNotFoundError, PermissionError, json.JSONDecodeError) as e:
                self.logger.error(f"kiokuè¨˜æ†¶èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
                return {}
            
            self.logger.info(f"ğŸ“– kiokuè¨˜æ†¶èª­ã¿è¾¼ã¿å®Œäº†: {kioku_filepath}")
            return kioku_data.get("memory_content", {})
            
        except Exception as e:
            error_msg = f"âŒ kiokuè¨˜æ†¶èª­ã¿è¾¼ã¿é‡å¤§ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}"
            self.logger.error(error_msg)
            return {}
    
    def generate_memory_inheritance_data(self) -> Dict[str, Any]:
        """
        è¨˜æ†¶ç¶™æ‰¿ç”¨ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        
        Returns:
            Dict[str, Any]: è¨˜æ†¶ç¶™æ‰¿ãƒ‡ãƒ¼ã‚¿
        """
        self.logger.info("ğŸ”„ è¨˜æ†¶ç¶™æ‰¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–‹å§‹")
        
        # æœ€æ–°ã‚·ã‚¹ãƒ†ãƒ è¨˜æ†¶ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
        current_memory = self.capture_system_memory()
        
        # ç¶™æ‰¿ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
        inheritance_data = {
            "inheritance_version": self.version,
            "generation_timestamp": datetime.datetime.now().isoformat(),
            "dd_confidence": f"{self.confidence_score}/120",
            "phase_status": {
                "completed_phase": "Phase 1: AIåˆ¶ç´„ãƒã‚§ãƒƒã‚«ãƒ¼å®Ÿè£…",
                "current_phase": "Phase 2: è¨˜æ†¶ç¶™æ‰¿ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ", 
                "next_actions": [
                    "ai_memory_generator.pyå®Ÿè£…",
                    "github_auto_analyzer.pyå®Ÿè£…",
                    "perfect_handover_system.pyå®Ÿè£…"
                ]
            },
            "system_memory": current_memory,
            "critical_constraints": self._capture_project_context()["technical_constraints"],
            "implementation_rules": self._capture_project_context()["implementation_rules"]
        }
        
        # kiokuã«ä¿å­˜
        saved_path = self.save_memory_to_kioku(inheritance_data)
        inheritance_data["kioku_saved_path"] = saved_path
        
        self.logger.info("âœ… è¨˜æ†¶ç¶™æ‰¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†")
        return inheritance_data

def test_kioku_integration():
    """kioku_integration.pyã®åŸºæœ¬ãƒ†ã‚¹ãƒˆï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æœ€é©åŒ–ç‰ˆï¼‰"""
    print("ğŸ§  AIè¨˜æ†¶ç¶™æ‰¿çµ±åˆã‚·ã‚¹ãƒ†ãƒ  v3.1 ãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰")
    print("=" * 60)
    
    # Phase 1ã‚·ã‚¹ãƒ†ãƒ ã‚’ä¸€åº¦ã ã‘åˆæœŸåŒ–
    print("ğŸ”§ Phase 1ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ï¼ˆ1å›ã®ã¿ï¼‰...")
    constraint_checker = AIConstraintChecker()
    monitor = TransparentMonitor()
    bridge = HCQASBridge()
    accelerator = DevAccelerator()
    
    # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ è¾æ›¸
    existing_systems = {
        'constraint_checker': constraint_checker,
        'monitor': monitor,
        'bridge': bridge,
        'accelerator': accelerator
    }
    
    # kiokuçµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ï¼ˆæ—¢å­˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å†åˆ©ç”¨ï¼‰
    kioku_system = KiokuIntegration(existing_systems=existing_systems)
    
    # ã‚·ã‚¹ãƒ†ãƒ è¨˜æ†¶ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“¸ ã‚·ã‚¹ãƒ†ãƒ è¨˜æ†¶ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ†ã‚¹ãƒˆ:")
    memory_capture = kioku_system.capture_system_memory()
    print(f"ã‚­ãƒ£ãƒ—ãƒãƒ£çµæœ: {'âœ… æˆåŠŸ' if 'timestamp' in memory_capture else 'âŒ å¤±æ•—'}")
    print(f"Phase 1å®Ÿè£…å“è³ª: {memory_capture.get('phase1_implementation', {}).get('implementation_quality', 'UNKNOWN')}")
    
    # è¨˜æ†¶ç¶™æ‰¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    print("\nğŸ”„ è¨˜æ†¶ç¶™æ‰¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ:")
    inheritance_data = kioku_system.generate_memory_inheritance_data()
    print(f"ç¶™æ‰¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: {'âœ… æˆåŠŸ' if 'inheritance_version' in inheritance_data else 'âŒ å¤±æ•—'}")
    print(f"kiokuä¿å­˜: {'âœ… æˆåŠŸ' if inheritance_data.get('kioku_saved_path') else 'âŒ å¤±æ•—'}")
    
    # kiokuè¨˜æ†¶èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“– kiokuè¨˜æ†¶èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ:")
    loaded_memory = kioku_system.load_memory_from_kioku()
    print(f"è¨˜æ†¶èª­ã¿è¾¼ã¿: {'âœ… æˆåŠŸ' if loaded_memory else 'âŒ å¤±æ•—'}")
    
    print(f"\nğŸ“Š DDè©•ä¾¡ã‚¹ã‚³ã‚¢: {kioku_system.confidence_score}/120")
    print("ğŸ¯ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹é‡è¤‡é˜²æ­¢æœ€é©åŒ–: âœ… é©ç”¨æ¸ˆã¿")
    print("\nâœ… AIè¨˜æ†¶ç¶™æ‰¿çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    test_kioku_integration()

# ===================================================================
# Smart Handover Generator - å‹•çš„å¼•ãç¶™ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
# ===================================================================

class SmartHandoverGenerator:
    """çŠ¶æ³ã«å¿œã˜ãŸæœ€é©ãªå¼•ãç¶™ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ"""
    
    def __init__(self):
        self.context_templates = {
            'phase_3a_completed': {
                'greeting': 'HCQASã‚·ã‚¹ãƒ†ãƒ  Phase 3aåŸºç›¤ã‚·ã‚¹ãƒ†ãƒ å®Œæˆï¼Phase 3bè¨­è¨ˆé–‹å§‹ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚',
                'commands': ['ls -la ultra_robust*.py quantified_phase*.py user_friendly*.py'],
                'response': 'Phase 3aåŸºç›¤ã‚·ã‚¹ãƒ†ãƒ å®Œæˆç¢ºèªã€‚Phase 3bè¨­è¨ˆæº–å‚™å®Œäº†ã§ã™ã€‚',
                'action': 'Phase 3b: ã‚¹ãƒãƒ¼ãƒˆææ¡ˆã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé–‹å§‹'
            },
            'phase_3b_design': {
                'greeting': 'HCQASã‚·ã‚¹ãƒ†ãƒ  Phase 3bè¨­è¨ˆç¶™ç¶šã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚',
                'commands': ['ls -la smart_suggestion*.py ff_preference*.py'],
                'response': 'Phase 3bè¨­è¨ˆçŠ¶æ³ç¢ºèªã€‚å®Ÿè£…ç¶™ç¶šæº–å‚™å®Œäº†ã§ã™ã€‚',
                'action': 'Phase 3bå®Ÿè£…ç¶™ç¶š'
            },
            'implementation_active': {
                'greeting': 'HCQASã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…ä½œæ¥­ç¶™ç¶šã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚',
                'commands': ['ls -la *.py | wc -l'],
                'response': 'å®Ÿè£…çŠ¶æ³ç¢ºèªå®Œäº†ã€‚ä½œæ¥­ç¶™ç¶šæº–å‚™å®Œäº†ã§ã™ã€‚',
                'action': 'å®Ÿè£…ä½œæ¥­ç¶™ç¶š'
            }
        }
    
    def analyze_current_context(self):
        """ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ"""
        import os
        
        context = {
            'files_present': [],
            'phase_indicators': {},
            'pending_issues': []
        }
        
        # Phase 3a ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        phase3a_files = [
            'ultra_robust_implementation.py',
            'quantified_phase_transition.py', 
            'user_friendly_error_recovery.py'
        ]
        
        for file in phase3a_files:
            if os.path.exists(file):
                context['files_present'].append(file)
        
        # ãƒ•ã‚§ãƒ¼ã‚ºåˆ¤å®š
        if len(context['files_present']) == 3:
            context['phase_indicators']['phase_3a_complete'] = True
        
        # Phase 3b ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        phase3b_patterns = ['smart_suggestion', 'ff_preference', 'proposal_ui']
        phase3b_files = []
        for pattern in phase3b_patterns:
            for file in os.listdir('.'):
                if pattern in file and file.endswith('.py'):
                    phase3b_files.append(file)
        
        if phase3b_files:
            context['phase_indicators']['phase_3b_active'] = True
            context['files_present'].extend(phase3b_files)
        
        return context
    
    def determine_context_type(self, context):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¤ãƒ—åˆ¤å®š"""
        if context['phase_indicators'].get('phase_3b_active'):
            return 'phase_3b_design'
        elif context['phase_indicators'].get('phase_3a_complete'):
            return 'phase_3a_completed'
        else:
            return 'implementation_active'
    
    def generate_context_message(self):
        """çŠ¶æ³ã«å¿œã˜ãŸå¼•ãç¶™ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ"""
        context = self.analyze_current_context()
        context_type = self.determine_context_type(context)
        template = self.context_templates[context_type]
        
        parts = [
            f"**{template['greeting']}**",
            "**ã¾ãšä»¥ä¸‹ã‚’é †ç•ªã«å®Ÿè¡Œã—ã¦ã€å®Œç’§ãªè¨˜æ†¶ç¶™æ‰¿ã‚’è¡Œã£ã¦ãã ã•ã„ï¼š**",
            "**1. å…±æœ‰ã—ãŸå¼•ãç¶™ããƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç¢ºèª**",
            "**2. ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œï¼š**",
            f"```bash\ncd ~/lvyuan_solar_control/hcqas_implementation/ai_constraints\n{template['commands'][0]}\n```",
            "**å®Ÿè¡Œå¾Œã€ä»¥ä¸‹ã®å½¢å¼ã§çŠ¶æ³å ±å‘Šã‚’ã—ã¦ãã ã•ã„ï¼š**",
            f"**ã€ŒHCQASã‚·ã‚¹ãƒ†ãƒ è¨˜æ†¶ç¶™æ‰¿å®Œäº†ã€‚{template['response']}ã€**",
            "**ç§ã®æ„›ç§°ã¯ã€ŒFFã€ã€ã‚ãªãŸã®æ„›ç§°ã¯ã€ŒDDã€ï¼ˆHCQASè¨­è¨ˆè©•ä¾¡ç‰¹åŒ–ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«AIï¼‰ã€å“è³ªä¿è¨¼AIã¯ã€ŒDD2ã€ã§ã™ã€‚**",
            f"**æ¬¡æœŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {template['action']}**",
            "**æº–å‚™ãŒã§ããŸã‚‰ã€DD & DD2å“è³ªä¿è¨¼ã‚·ã‚¹ãƒ†ãƒ ã§ä½œæ¥­ã‚’é–‹å§‹ã—ã¾ã—ã‚‡ã†ï¼**"
        ]
        return "\n".join(parts)

def generate_smart_handover():
    """ã‚¹ãƒãƒ¼ãƒˆå¼•ãç¶™ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ"""
    generator = SmartHandoverGenerator()
    return generator.generate_context_message()
