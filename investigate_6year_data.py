#!/usr/bin/env python3
# 6å¹´åˆ†ãƒ‡ãƒ¼ã‚¿å¾¹åº•èª¿æŸ»ï¼ˆå®Œå…¨éç ´å£Šçš„ï¼‰
import datetime
import os
import glob
import json

def investigate_6year_data():
    """6å¹´åˆ†ãƒ‡ãƒ¼ã‚¿å¾¹åº•èª¿æŸ»"""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    print(f"ğŸ” 6å¹´åˆ†ãƒ‡ãƒ¼ã‚¿å¾¹åº•èª¿æŸ»é–‹å§‹ {timestamp}")
    print("=" * 70)
    
    # 1. å…¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ¢ç´¢
    print(f"ğŸ“ å…¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ¢ç´¢:")
    
    # ãƒ‡ãƒ¼ã‚¿æ ¼ç´å ´æ‰€å€™è£œ
    data_locations = [
        "data/",
        "historical_data/",
        "backup_data/", 
        "archive/",
        "6year_data/",
        "past_data/",
        "github_data/",
        "./",
        "../"
    ]
    
    found_data = {}
    
    for location in data_locations:
        if os.path.exists(location):
            print(f"  ğŸ“‚ {location}: å­˜åœ¨ç¢ºèª")
            
            # JSONã€CSVã€SQLiteãƒ•ã‚¡ã‚¤ãƒ«æ¢ç´¢
            patterns = ["*.json", "*.csv", "*.db", "*.sqlite", "*historical*", "*6year*"]
            
            for pattern in patterns:
                files = glob.glob(os.path.join(location, pattern))
                if files:
                    found_data[location] = found_data.get(location, []) + files
        else:
            print(f"  âŒ {location}: æœªç™ºè¦‹")
    
    # 2. ç™ºè¦‹ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°åˆ†æ
    print(f"\nğŸ“Š ç™ºè¦‹ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°åˆ†æ:")
    
    total_files = 0
    total_size = 0
    oldest_date = None
    newest_date = None
    
    for location, files in found_data.items():
        print(f"\nğŸ“‚ {location}:")
        location_files = len(files)
        location_size = 0
        
        for file_path in files[:10]:  # æœ€åˆã®10å€‹ã‚’è©³ç´°ç¢ºèª
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                mtime = os.path.getmtime(file_path)
                mtime_date = datetime.datetime.fromtimestamp(mtime)
                
                location_size += file_size
                total_files += 1
                total_size += file_size
                
                if oldest_date is None or mtime_date < oldest_date:
                    oldest_date = mtime_date
                if newest_date is None or mtime_date > newest_date:
                    newest_date = mtime_date
                
                print(f"    ğŸ“„ {os.path.basename(file_path)}: {file_size:,}ãƒã‚¤ãƒˆ ({mtime_date.strftime('%Y-%m-%d')})")
        
        if location_files > 10:
            print(f"    ... ä»–{location_files - 10}å€‹")
        
        print(f"    ğŸ“Š å°è¨ˆ: {location_files}ãƒ•ã‚¡ã‚¤ãƒ«, {location_size:,}ãƒã‚¤ãƒˆ")
    
    # 3. æ­´å²ãƒ‡ãƒ¼ã‚¿æœŸé–“ç¢ºèª
    print(f"\nğŸ“… æ­´å²ãƒ‡ãƒ¼ã‚¿æœŸé–“ç¢ºèª:")
    if oldest_date and newest_date:
        duration = (newest_date - oldest_date).days
        duration_years = duration / 365.25
        
        print(f"  ğŸ“Š æœ€å¤ãƒ‡ãƒ¼ã‚¿: {oldest_date.strftime('%Y-%m-%d')}")
        print(f"  ğŸ“Š æœ€æ–°ãƒ‡ãƒ¼ã‚¿: {newest_date.strftime('%Y-%m-%d')}")
        print(f"  ğŸ“Š ãƒ‡ãƒ¼ã‚¿æœŸé–“: {duration}æ—¥é–“ ({duration_years:.1f}å¹´)")
        print(f"  ğŸ“Š ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}")
        print(f"  ğŸ“Š ç·ãƒ‡ãƒ¼ã‚¿é‡: {total_size:,}ãƒã‚¤ãƒˆ")
        
        if duration_years >= 5:
            print(f"  ğŸ‰ 6å¹´åˆ†ç›¸å½“ãƒ‡ãƒ¼ã‚¿ç™ºè¦‹ï¼")
        else:
            print(f"  âš ï¸ 6å¹´åˆ†ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {duration_years:.1f}å¹´åˆ†ã®ã¿")
    else:
        print(f"  âŒ ãƒ‡ãƒ¼ã‚¿æœŸé–“ç‰¹å®šä¸å¯")
    
    # 4. GitHubãƒ»å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿æ¢ç´¢
    print(f"\nğŸ” GitHubãƒ»å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿æ¢ç´¢:")
    
    # GitHubé–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    github_patterns = [
        "*github*",
        "*git*",
        "*.git",
        "README*",
        "*history*",
        "*backup*"
    ]
    
    github_files = []
    for pattern in github_patterns:
        github_files.extend(glob.glob(pattern))
    
    if github_files:
        print(f"  ğŸ“‚ GitHubé–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«:")
        for gfile in github_files[:5]:
            print(f"    ğŸ“„ {gfile}")
    else:
        print(f"  âŒ GitHubé–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹")
    
    # 5. SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèª
    print(f"\nğŸ—„ï¸ SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèª:")
    db_files = glob.glob("*.db") + glob.glob("*.sqlite") + glob.glob("*/*.db") + glob.glob("*/*.sqlite")
    
    if db_files:
        for db_file in db_files:
            if os.path.exists(db_file):
                db_size = os.path.getsize(db_file)
                print(f"  ğŸ“Š {db_file}: {db_size:,}ãƒã‚¤ãƒˆ")
                
                # SQLiteãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª
                try:
                    import sqlite3
                    conn = sqlite3.connect(db_file)
                    cursor = conn.cursor()
                    cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
                    tables = cursor.fetchall()
                    conn.close()
                    
                    if tables:
                        print(f"    ğŸ“‹ ãƒ†ãƒ¼ãƒ–ãƒ«: {[t[0] for t in tables]}")
                    else:
                        print(f"    âŒ ãƒ†ãƒ¼ãƒ–ãƒ«ãªã—")
                except Exception as e:
                    print(f"    âŒ DBç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print(f"  âŒ SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœªç™ºè¦‹")
    
    # 6. æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ç¢ºèª
    print(f"\nğŸ¤– æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ç¢ºèª:")
    
    ml_file = "hanazono_ml_enhancement_20250617_234033.py"
    if os.path.exists(ml_file):
        try:
            with open(ml_file, 'r', encoding='utf-8') as f:
                ml_content = f.read()
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹æ¤œç´¢
            data_paths = []
            lines = ml_content.split('\n')
            for line in lines:
                if 'data' in line.lower() and ('.json' in line or '.csv' in line or '.db' in line):
                    data_paths.append(line.strip())
            
            if data_paths:
                print(f"  ğŸ“‹ MLè¨­å®šãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹:")
                for path in data_paths[:5]:
                    print(f"    {path}")
            else:
                print(f"  âŒ MLãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹æœªç¢ºèª")
                
        except Exception as e:
            print(f"  âŒ MLç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
    
    # 7. æ¨å¥¨è§£æ±ºç­–
    print(f"\n" + "=" * 70)
    print(f"ğŸ¯ 6å¹´åˆ†ãƒ‡ãƒ¼ã‚¿æ´»ç”¨è§£æ±ºç­–:")
    print(f"=" * 70)
    
    if duration_years >= 5 if 'duration_years' in locals() else False:
        print(f"âœ… è§£æ±ºç­–: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’MLç³»ã«çµ±åˆ")
        solutions = [
            "æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ä¿®æ­£",
            "æ­´å²ãƒ‡ãƒ¼ã‚¿ã®çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›",
            "MLã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹6å¹´åˆ†ãƒ‡ãƒ¼ã‚¿åˆ†æå®Ÿè¡Œ"
        ]
    else:
        print(f"ğŸ” è§£æ±ºç­–: 6å¹´åˆ†ãƒ‡ãƒ¼ã‚¿æ‰€åœ¨ç‰¹å®š")
        solutions = [
            "GitHubå±¥æ­´ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å¾©æ—§",
            "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã®å¾©å…ƒ",
            "å¤–éƒ¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—",
            "æ‰‹å‹•ãƒ‡ãƒ¼ã‚¿çµ±åˆä½œæ¥­"
        ]
    
    for i, solution in enumerate(solutions, 1):
        print(f"   {i}. {solution}")
    
    return {
        "total_files": total_files,
        "duration_years": duration_years if 'duration_years' in locals() else 0,
        "data_locations": list(found_data.keys()),
        "needs_data_integration": duration_years < 5 if 'duration_years' in locals() else True
    }

if __name__ == "__main__":
    investigate_6year_data()
